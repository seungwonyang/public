#------------------------------------------------------------------------------------------
# Seungwon Yang <seungwon@vt.edu>
# PARC Internship, Dept. of CS, Virginia Tech
# Description: this script adds a list of JSON records from an input file 
#              (generated by mongodb) to mysql db
# Usage: >>python mongoNYT.py 
#------------------------------------------------------------------------------------------

import math
import json
import MySQLdb
from StringIO import StringIO
import re
import urllib2
from pymongo import Connection


def json2mongo(jsonfile):
    connection = Connection()
    # db = connection.provisdb
    db = connection.nyt
    # collection = db.opencalais_test
    # collection = db.opencalais_full
    collection = db.nyttest
    jsonRecords = open(jsonfile).read()
    jsonLoaded = json.loads(jsonRecords)
    jsonList = jsonLoaded["response"]["docs"]
    index = 1
    for item in jsonList:
        # if (index > 400):
        #     break
        print "Index: %d ----------\n" % (index)
        # print item
        try:
            if (item["source"] == "NYT"):
                collection.insert(item)   
            # if (item["source"] == "NYT") and (item["opencalais"]):
            #     collection.insert(item)   
                # index += 1 
        except:
            pass
        index += 1

def extIDs(collection):
    id_li = [item["id"] for item in collection.find().limit(10)]
    for i in id_li:
        print i
    # jsonRecords = open(jsonfile).read()
    # jsonLoaded = json.loads(jsonRecords)
    # jsonList = jsonLoaded["response"]["docs"]
    # index = 1
    # for item in jsonList:
    #     # if (index > 400):
    #     #     break
    #     print "Index: %d ----------\n" % (index)
    #     # print item
    #     try:
    #         if (item["source"] == "NYT"):
    #             collection.insert(item)   
    #         # if (item["source"] == "NYT") and (item["opencalais"]):
    #         #     collection.insert(item)   
    #             # index += 1 
    #     except:
    #         pass
    #     index += 1

def extText(collection, idList):
    # for each in idList[:10]:
    for each in idList:
        print each
        each = str(each)
        # grab a single record with the id
        singleRec = collection.find_one({"id":each})
        uni_title = u""+singleRec["titleText"]
        uni_text = u""+singleRec["text"]

        title_and_text = singleRec["titleText"] + " " + singleRec["text"]
        # title_and_text = singleRec["titleText"] + " " + singleRec["text"]
        print "\n\n\n"
        # print title_and_text

        out_filename = each + ".txt"
        out_path = "../NYT_3000/" + out_filename
        fo = open(out_path, "w")
        fo.write(title_and_text.encode("utf-8"))
        fo.close()

    # id_li = [item["text"] for item in collection.find().limit(1)]
    # for i in id_li:
    #     print i

def extMetadata(collection, idList, cur):
    i = 1
    for doc_id in idList:
    # for each in idList[1596:]:
        print "Index: %d    Doc_id: %s" % (i, doc_id)
        doc_id = str(doc_id)
        # grab a single record with the id
        singleRec = collection.find_one({"id":doc_id})
        # uni_title = u""+singleRec["titleText"]
        # uni_text = u""+singleRec["text"]
        # title_and_text = singleRec["titleText"] + " " + singleRec["text"]

        opencalais_li = singleRec["opencalais"][1:-1].lower().split('", "')   
        organizations_li = singleRec["organizations"][1:-1].lower().split('","')    
        people_li = singleRec["people"][1:-1].lower().split('","')  
        locations_li = singleRec["locations"][1:-1].lower().split('","')     
        descriptors_li = singleRec["descriptors"][1:-1].lower().split('","')     
        names_li = singleRec["names"][1:-1].lower().split('","')     
 
        opencalais = ";".join([re.sub(r'[^\w]', ' ', item) for item in opencalais_li])   
        organizations = ";".join([re.sub(r'[^\w]', ' ', item) for item in organizations_li])
        people = ";".join([re.sub(r'[^\w]', ' ', item) for item in people_li])   
        locations = ";".join([re.sub(r'[^\w]', ' ', item) for item in locations_li])   
        descriptors = ";".join([re.sub(r'[^\w]', ' ', item) for item in descriptors_li])   
        names = ";".join([re.sub(r'[^\w]', ' ', item) for item in names_li])   

        nyt_manual_topics = organizations + ";" + people + ";" + locations + ";" + descriptors + ";" + names   

        # print "\n\n\n"
        # # print title_and_text
        print "opencalais: \n%s" % opencalais
        print "organizations: \n%s" % organizations
        print "people: \n%s" % people
        print "locations: \n%s" % locations
        print "descriptors: \n%s" % descriptors
        print "names: \n%s" % names
        print "nyt_manual_topics: \n%s" % nyt_manual_topics

        # write extracted metadata into mysql table 'nyt_3000'
        # query = "update nyt_3000 set opencalais='" + opencalais + "' where doc_id=" + str(doc_id)

        query = "update nyt_3000 set opencalais='" + opencalais + "', organizations='" + organizations + "', people='" + people + "', locations='" + locations + "', descriptors='" + descriptors + "', names='" + names + "', nyt_manual_topics='" + nyt_manual_topics + "' where doc_id=" + str(doc_id)

        cur.execute(query)
        i += 1

        # out_filename = each + ".txt"
        # out_path = "../NYT_3000/" + out_filename
        # fo = open(out_path, "w")
        # fo.write(title_and_text.encode("utf-8"))
        # fo.close()

def main():
    fi = open("NYT_IDs.txt", "r")
    li = fi.read().split()
    fi.close()
    # connection to mongodb --------------------------//
    connection = Connection()
    mongodb = connection.nyt
    collection = mongodb.nyttest

    # connection to mysqldb --------------------------//
    dbuser = "db_user_name"
    dbpasswd = "db_passwd"
    hostname = "db_hostname"
    dbname = "db_name"
    dbtable = "db_table"
    mysqldb = MySQLdb.connect(host=hostname, user=dbuser, passwd=dbpasswd, db=dbname)
    cur = mysqldb.cursor()


    # # extract ids from 83,000 records
    # extIDs(collection)

    # extText(collection, li)
    # print li

    extMetadata(collection, li, cur)

    # # create multiple json files, where each contains 1000 doc
    # for page in range(1,83): # process 83,741 records (each iteration for 1000 rec.)
    #     # rows = 1000
    #     filename = "opencalais_" + str(page) + ".json"
    #     # fout = open(filename, "w")
    #     # url = "http://solr_server_hostname:solr_server_port/solr/select/?wt=json&q=opencalais:*%20AND%20source:NYT&fl=score&rows=" + str(rows) + "&start=" + str(rows * page)
    #     # fi = urllib2.urlopen(url)
    #     # ffi = fi.read()
    #     # fout.write(ffi)
    #     # fout.close()


    #     print "File number: %d --------------" % page
    #     json2mongo(filename)

if __name__ == "__main__":
    main()
